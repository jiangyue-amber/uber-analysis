{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T05:39:14.494431Z",
     "start_time": "2025-02-06T05:39:14.470358Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('dataset_2.csv', low_memory = False)\n",
    "df.head()\n",
    "\n",
    "#feature engineering\n",
    "df['Lag_1'] = df['Trips Completed'].shift(1)  # Lag 1 \n",
    "df['Lag_7'] = df['Trips Completed'].shift(7)  # Lag 7 (Weekly)\n",
    "df['Lag_30'] = df['Trips Completed'].shift(30)  # Lag 30 (Monthly)\n",
    "df.dropna(inplace=True) \n",
    "df['Accept Rate'] = df['Accept Rate'].str.replace('%', '').astype(float) / 100\n",
    "df['Trips per Hour'] = df['Trips Completed'] / df['Supply Hours']\n",
    "\n",
    "\n",
    "X = df[['Accept Rate', 'Supply Hours', 'Trips per Hour', 'Rating','Lag_1', 'Lag_7', 'Lag_30']]\n",
    "y = df['Trips Completed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decision Tree (Harita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decision Tree (Harita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ARIMA (Andrew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. RNN (Amber)\n",
    "- RNNs mimic how humans process sequential data. \n",
    "- RNNs have a \"memory\" that allows them to remember previous inputs and use that information to make predictions. \n",
    "- RNNs connect the output of one step to the input of the next step, unlike traditional neural networks that process inputs and outputs independently. \n",
    "- RNNs use a hidden layer and hidden state to achieve this output-to-input transition. \n",
    "\n",
    "- Since our data is not a sequential data, RNN may not be the best model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "RNN - MSE: 25.54, R²: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy array and reshape , RNNs expect input in 3D shape → (samples, timesteps, features)\n",
    "# samples: rows in the dataset (X_train.shape[0], here is 71)\n",
    "# timesteps: how many previous time steps are considered for each prediction \n",
    "# (here is 1, meaning that each input sample only depends on the current data point rather than historical values)\n",
    "# features: columns in the dataset(X_train.shape[1], here is 7)\n",
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the RNN model\n",
    "# Sequential([...]): Creates a sequential stack of layers.\n",
    "# 50: each of the 50 neuron stores a hidden state and updates it at every timestep.\n",
    "# 'relu': apply ReLU activation function at each neuron to introduce non-linearity, helping capture complex patterns\n",
    "# Dense(1): Fully connected output layer with 1 neuron (predicting a single value).\n",
    "rnn_model = Sequential([SimpleRNN(50, activation='relu', input_shape=(1, X_train.shape[2])), Dense(1)])\n",
    "# Optimizer → How the model updates weights. \n",
    "# (adam adjusts learning rates dynamically, speeding up training and prevents getting stuck in bad local minima.)\n",
    "# Loss Function → How the model measures its error.\n",
    "rnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# the extra parameters are specific to models that require iterative training using optimization techniques like backpropagation (e.g., neural networks)\n",
    "# epochs: How many times the model should see the entire dataset during training.\n",
    "# batch_size: The number of samples the model uses to update its weights in one step (mini-batch training).\n",
    "# verbose: Controls the output of the training process (e.g., how much information to show during training).\n",
    "rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "rnn_pred=rnn_model.predict(X_test)\n",
    "mse, r2 = mean_squared_error(y_test, rnn_pred), r2_score(y_test, rnn_pred)\n",
    "print(f\"RNN - MSE: {mse:.2f}, R²: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. XGBoost (Gary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
